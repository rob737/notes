--- Concurrency (130 pages)

concurrency is basically dividing a task into multiple tasks that may or may not execute at the same time.


********************* Homework *********************

-- Understand how threads are created and started : 

   basically understand native code thread.start() 

-- Understand how Future's get() method behaves, does it block untill all tasks are ready or it blocks untill corresponding future task is ready.
 Ans : we call get on a particular future object so it waits untill that particular Future is ready.

***************************************************

-- Moore's law :

The number of transistors that can be placed on an IC doubles after every two years.

-- process :

A process is a self-contained program running within its own address space. 
A multitasking operating system can run more than one process (program) at a time 
by periodically switching the CPU from one process to another, 
while making it look as if each process is chugging along on its own.

In contrast, concurrent systems like the one used in Java share resources like memory and I/O, so the fundamental difficulty in writing multithreaded programs 
is coordinating the use of these resources between different thread-driven tasks, 
so that they cannot be accessed by more than one task at a time.

Each task executes as a process in its own address space, so there’s no possibility of interference between tasks. 
More importantly, there’s no need for the tasks to communicate with each other because they’re all completely independent.

-- Java doesn't support creating multiple processes but multiple threads within a process.

Instead of forking external processes in a multitasking operating system, 
threading creates tasks within the single process represented by the executing program.

Java’s threading is preemptive, which means that a scheduling mechanism provides time slices for each thread, 
periodically interrupting a thread and context switching to another thread so that each one is given a reasonable amount of time to drive its task.

Using multithreading, each of these independent tasks (also called subtasks) is driven by a thread of execution. 

"A thread is a single sequential flow of control within a process."

A single process can thus have multiple concurrently executing tasks, but you program as if each task has the CPU to itself.

so basically, even multithreaeding guarantees concurrent execution but not simultaneous execution.


--- Task :

Task is performed by threads.
To define a task simply implement Runnable.

Thread.yield() -- signals thread executor to schedule other task which is not mandatory though.

--- Thread class :

Each Thread "registers" itself so there is actually a reference to it someplace, 
and the garbage collector can’t clean it up until the task exits its run( ) and dies.

RunnableExample runnableExample = new RunnableExample();
Thread thread = new Thread(runnableExample);

Flow is like below :

1. Create a thread using syntax : Thread t = new Thread();

2. Now, you have to assign a task or critical section that this thread must execute which is defined by Runnable interface's run method.

3. t = new Thread(<Runnable object reference>)

-- native keyword

e.g. private native void start0() 

The native keyword in Java is used in method declarations to indicate that the method is implemented in a platform-dependent way,
 typically in another programming language like C or C++. When a method is declared as native,
 it means that the implementation of that method is provided by a non-Java source code, and it must be linked to the Java code at runtime.
 
 
 



--- Executors :

Note : It is present in java.util.concurrent package.

Before Executors, client directly manages lifecycle of a thread.

After Executors, client delegates this responsibility to Executor,
i.e. we can use Executor instead of directly creating threads (It uses command design pattern).

-- FixedThreadPool Executor Service - upfront decide number of threads that is needed.
Syntax : ExecutorService exec = Executors.newFixedThreadPool(<num of threads>);

-- CachedThreadPool Executor Service - depends on the load underlying library decides the number of threads that needs to be executed.
Syntax : ExecutorService exec = Executors.newCachedThreadPool();

e.g. this will create 15 threads for CachedThreadPool:

for(int i =0; i<15; i++)
            executorService.execute(new RunnableExample());
			
-- SingleThreadExecutor : It provisions only one thread and it serializes the tasks that is submitted to it and maintain an inherent queue for the same.
Syntax : ExecutorService exec = Executors.newSingleThreadExecutor();

Note: ExecutorService extends Executor interface and implementation class of execute is ThreadPoolExecutor.

Note : From ThreadPoolExecutor documentation :

		 * If fewer than corePoolSize threads are running, try to
         * start a new thread with the given command(Runnable object) as its first
         * task
		 
		 For FixedThreadPool, it is defined by number of threads that is passed as parameter in Syntax above.
		 For CachedThreadPool, it is decided by JVM at runtime based on the maximumPoolSize value.
		 
Note : Volatile keyword

In Java, the volatile keyword is used to indicate that a variable's value may be modified asynchronously by multiple threads. 
When a variable is declared as volatile, the Java memory model ensures that any write to that variable is immediately visible to all other threads 
that access that variable.

Note: It doesn't guarantee thread safe behaviour but synchronized keyword does.	 

volatile basically denotes that variable would be stored in memory and not in Thread's local stack.

--- Producing return values from a task :

A Runnable is a separate task that performs work but it doesn't return a value.
If we want our task to return a value then we need to implement Callable interface (this is Generic i.e. Callable<Some Type>) rather than Runnable interface.



***** Creation of thread at OS level ******

The creation of a thread involves several steps:

1. Allocation of resources: The kernel allocates the necessary resources to support a new thread, 
including a unique thread identifier, a stack, and a register context.

2. Setting up the thread's initial state: The kernel sets up the initial state of the new thread, 
including setting the program counter to the starting address of the thread's code.

3. Registering the thread with the scheduler: The kernel registers the new thread with the scheduler, 
which is responsible for determining which thread should be executed next.

4. Scheduling the thread: Once the new thread has been registered with the scheduler, 
the scheduler determines when to start executing the thread based on a variety of factors, 
including the priority of the thread and the availability of system resources.

5. Execution: Once the thread is scheduled to run, the kernel sets up the necessary hardware context to allow the thread to execute, 
and the thread begins executing its code.

--- Sleeping :

Important :
The call to sleep( ) can throw an InterruptedException, and you can see that this is caught in run( ). 
Because exceptions won’t propagate across threads back to main( ), 
you must locally handle any exceptions that arise within a task.

Syntax :

In run() method :
TimeUnit.MILLISECONDS.sleep(100);

--- Priority :

The priority of a thread conveys the importance of a thread to the scheduler. 
Although the order in which the CPU runs a set of threads is indeterminate, 
the scheduler will lean toward running the waiting thread with the highest priority first. 
However, this doesn’t mean that threads with lower priority aren’t run (so you can’t get deadlocked because of priorities).
Lower-priority threads just tend to run less often.

Syntax : 
Thread.currentThread().setPriority(priority);

--- Yield :

When you call yield( ), you are suggesting that other threads of the same priority might be run.
This is just a hint to scheduler and doesn't guarantee anything.

-- yield() vs sleep() :

sleep : It pauses the thread for specified time during which thread is not scheduled by the scheduler i.e. it isn't active and ready to run during sleep timing.
yield : It hints scheduler that it can be context switched with other thread but it will remain active and ready to run.


--- Daemon threads :

Daemon thread runs in the background and is active untill the process that spawned this thread is running.
Syntax :
Thread thread = new Thread();
thread.setDaemon(true);

Note :::

You should be aware that daemon threads will terminate their run( ) methods without executing finally clauses.

--- Terminology :

Thread has a task (class that implements Runnable).

--- Joining a thread :

If a thread calls t.join( ) on another thread t, then the calling thread is suspended until the target thread t finishes (when t.isAlive( ) is false). 

--- To make UI non blocking :

use daemon process and put the calculation inside a run( ) method to allow it to be preempted.

--- Sharing resources :

Mutex (Mutual Exclusion) : Piece of code that is serialized.

Synchronized : keyword that is put on a method to prevent race condition.
Note (Important) : All synchronized keyword defined method will be blocked/locked if a thread is currently executing any synchronized method of
that object within a task.

All objects implicitly contain a single lock which is called a monitor.
This monitor object is shared across all synchronized methods and that's why only one synchronized method can be executed at a time within a task by a thread. 

Note :: There is also a single separate lock for static members of the class which are synchronized.

Very Important : 
 If you have more than one method in your class that deals with the critical data, you must synchronize all relevant methods.
 If you synchronize only one of the methods, then the others are free to ignore the object lock and can be called with impunity. 
 This is an important point: Every method that accesses a critical shared resource must be synchronized or it won’t work right.
 
****************** Homework ****************************

use synchronize keyword to generate odd and even numbers in alternate order.
solution : we would need wait() and notify() method for it.

--- Explicit lock objects :

Lock object must be explicitly created, locked and unlocked.

Syntax :

private Lock lock = new ReentrantLock();

lock.lock() ; from this line untill lock.unlock is called, it becomes a critical section and thread safety is ensured.
lock.unlock()

Important :::
When you are using Lock objects, it is important to internalize the idiom shown here: Right after the call to lock( ), 
you must place a try-finally statement with unlock( ) in the finally clause—this is the only way to guarantee that the lock is always released. 
Note that the return statement must occur inside the try clause to ensure that the unlock( ) doesn’t happen too early and expose the data to a second task.

ReentrantLock can be used to decide whether lock is required or not and also lock can be attained for specific time duration.

--- Atomicity and volatility :

Atomicity : Once operation starts then it can't be interrupted by thread scheduler until it finishes or errored out.

For multiprocessor systems i.e. multi-core(CPU) on a motherboard, visibility can be a problem for atomic operations as CPU's cache can store the result.
The synchronization mechanism, on the other hand, forces changes by one task on a multiprocessor system to be visible across the application.

Volatile keyword also guarantees this behaviour, it ensures that value is written on memory and read from memory.
Even synchronization guarantees this behavaiour.

Note : volatile doesn't work when value of a field depends on the previous value (e.g. counter).

Note : javap -c <Java filename> This command can be used to get JVM instructions of Java class. 

--- Atomic Classes :

Examples are AtomicInteger, AtomicLong, AtomicReference etc which provides methods which guarantees atomic methods.

e.g. AtomicInteger atomicInteger = new AtomicInteger(0);
     atomicInteger.addAndGet(2);
Above ensures that addition and storage happens atomically.

--- Critical Sections :

A part of method instead of complete method can be synchronized using a lock object.

Example :

public void increment() {
 Pair temp;
 synchronized(this) {
  p.incrementX();
  p.incrementY();
  temp = getPair();
 }
 store(temp);
}


Note: Instead of this, you can use any object.
Example :
private Object syncObject = new Object();


Doubt : Just like synchronized method, does synchronize block also doesn't allow other synchronize block or methods to be executed simultaneously?

Answer : Yes, other blocks and methods will be blocked as it is using the same object to perform locking mechanism.
So, if we don't want to block it then we can use locks on different objects.

--- Thread Local Storage :

OS creates a region of memory for each thread in RAM which basically serves as Thread local storage.

Thread local objects are stored as static fields and are accessed only via get() and set() methods of ThreadLocal class.

--- Thread states :

There are 4 stages of a thread :

1. New : state when thread is being created, resources being allocated and is ready for scheduler to pick it up.

2. Runnable : Thread is ready to be executed immediately if scheduler schedules it.

3. Blocked : In blocked state e.g. sleep, even though scheduler tries to schedule it, it will not run.

4. Dead : Either interrupted or completed execution of run() method.

-- Blocked state :

1. using sleep()
2. using wait() -- thread will remain in blocked state unless notify() or notifyAll() is called.
3. Thread is waiting for some I/O task to complete.
4. Thread is waiting on a synchronized method or block to wait.

Note : Verify if thread blocked due to I/O or waiting for acquiring lock can be interrupted or not.

Note : Tasks blocked on ReentrantLock object lock can be interrupted.


--- wait(), notify() and notifyAll() :

Above three provides a way to co-ordinate between different threads.

********* Homework ************

Generate even and odd number in alternate order using above methods.

wait() - blocks the execution of current thread unless notified by notify() or notifyAll().

Note: sleep() and yield() doesn't relinquish lock but wait() does.

Basically, wait() can be defined as follows :

"I’ve done all I can right now, so I’m going to wait right here, but I want to allow other synchronized operations to take place if they can."

Note: We can only call wait(), notify() and notifyAll() only within synchronized method or block.

Note : After wait() is over execution starts after the line where wait was defined. This makes sense as PC would store current instruction address
       during context switch.


--- Synchronized data strucutres :

synchronized queue, which only allows one task at a time to insert or remove an element. 
This is provided for you in the java.util.concurrent.BlockingQueue interface, 
which has a number of standard implementations. You’ll usually use the LinkedBlockingQueue, 
which is an unbounded queue; the ArrayBlockingQueue has a fixed size, so you can only put so many elements in it before it blocks.

Note : Blocking queues can solve a remarkable number of problems in a much simpler and more reliable fashion than wait( ) and notifyAll( ).
       e.g. Producer/consumer problem can be solved using BlockingQueue.


--- Semaphore :

Normal lock only allows one thread at a time to access the synchronized resource but semaphores maintain a count of n objects/threads to access the resource.

Example : connection pool can be implemented using this concept.

Semaphore is available in java.util.concurrency package.

functions : Semaphore semaphore = new Semaphore(size,true);
			semaphore.acquire(); // to acquire resource
			semaphore.release(); // to release resource
			
--- Optimistic Locking :

Using Atomic classes provided by java e.g. AtomicInteger : compareAndSet.

--- LockFree Algorithms for optimistic locking :

Why do we even need Lock free algorithms even though we have locks:

1. Overhead because of context switching as threads wait and that CPU cycle can be used for other operations.
2. Can result in deadlock
3. Can result in priority inverion : 
   UI - higher priority thread
   documentSaver - lower priority thread
   if lower priority thread gets interrupted without releasing lock then higher priority thread will not get the access to critical section.
4. Slow critical section because synchronized block if lock is obtained on the same object blocks access to all synchronized methods so 
   if any synchronized method is very slow and thread is executing that method then it will lead to overall slowness.   


What lock free implementation like AtomicInteger does ?

It utilize kernel functions that are atomic once it gets converted to Instruction Set Architecture 
e.g. AtomicInteger class uses compare and swap ISA to ensure atomicity.
     and it stores variable as volatile such that variable is stored directly in common address space in memory and not in individual thread stack.
	 
	 It is present in java.util.concurrent.atomic library.


Note :  

 If two threads try to update the value of the atomic integer at the same time, 
 only one of them will succeed, while the other will fail and have to retry the operation.
 
 Note : Understanding compare and swap :
 
 1. OS reads memory location value from main memory and puts it into register.
 
 2. It performs some checks and then writes it back to memory location.
 
 When multiple threads try to perform a CAS operation on the same memory location simultaneously, 
 only one thread will succeed in updating the memory location.
 
 other threads will fail and retry mechanism needs to be introduced.
 so, ultimately the reason that it is allowing only one thread to perfrom update operation as part of CAS and failing others 
 ensures that there is no data inconsistency.
 
 Cache coherance is basically following :
 1. every CPU(processor) has multiple memory storages like registers, L1/L2 caches etc.
 2. when any operation is performed data is read into a cache and it's marked as "shared"
 3. if it is modified then it should be avaialble to all other cache and marked as "modified".
 4. other CPU seeks permission from this CPU to read data from it's cache as it.
 
 
	 